{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d84c95e",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b9b1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import dependencies\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6405c623",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_tokenize = '''The most popular platform for creating Python programmes that use human language\n",
    "                    data is called NLTK. Along with a collection of text processing libraries for categorization,\n",
    "                    tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for \n",
    "                    industrial-strength NLP libraries, and an active discussion forum, it offers simple \n",
    "                    interfaces to more than 50 corpora and lexical resources, including WordNet.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7997881b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/gouravsinghbais/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -- OPTIONAL -- If punkt is not installed please install it before running the NLTK tokenizer\n",
    "import ssl \n",
    "try:\n",
    "    _create_unverified_http_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_http_context\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c0944a",
   "metadata": {},
   "source": [
    "## Word Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "855cc3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Words: ['The', 'most', 'popular', 'platform', 'for', 'creating', 'Python', 'programmes', 'that', 'use', 'human', 'language', 'data', 'is', 'called', 'NLTK', '.', 'Along', 'with', 'a', 'collection', 'of', 'text', 'processing', 'libraries', 'for', 'categorization', ',', 'tokenization', ',', 'stemming', ',', 'tagging', ',', 'parsing', ',', 'and', 'semantic', 'reasoning', ',', 'wrappers', 'for', 'industrial-strength', 'NLP', 'libraries', ',', 'and', 'an', 'active', 'discussion', 'forum', ',', 'it', 'offers', 'simple', 'interfaces', 'to', 'more', 'than', '50', 'corpora', 'and', 'lexical', 'resources', ',', 'including', 'WordNet', '.']\n"
     ]
    }
   ],
   "source": [
    "# apply NLTK word tokenizer\n",
    "word_tokens = nltk.word_tokenize(text_to_tokenize)\n",
    "print('Tokenized Words:', word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77583c6e",
   "metadata": {},
   "source": [
    "## Sentence Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "925dbd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentences: ['The most popular platform for creating Python programmes that use human language\\n                    data is called NLTK.', 'Along with a collection of text processing libraries for categorization,\\n                    tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for \\n                    industrial-strength NLP libraries, and an active discussion forum, it offers simple \\n                    interfaces to more than 50 corpora and lexical resources, including WordNet.']\n"
     ]
    }
   ],
   "source": [
    "# apply NLTK sentence tokenizer\n",
    "sentence_tokens = nltk.sent_tokenize(text_to_tokenize)\n",
    "print('Tokenized Sentences:', sentence_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426783a0",
   "metadata": {},
   "source": [
    "## Check Tokens Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3195253d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Count Dictionary: {'The': 1, 'most': 1, 'popular': 1, 'platform': 1, 'for': 3, 'creating': 1, 'Python': 1, 'programmes': 1, 'that': 1, 'use': 1, 'human': 1, 'language': 1, 'data': 1, 'is': 1, 'called': 1, 'NLTK': 1, '.': 2, 'Along': 1, 'with': 1, 'a': 1, 'collection': 1, 'of': 1, 'text': 1, 'processing': 1, 'libraries': 2, 'categorization': 1, ',': 9, 'tokenization': 1, 'stemming': 1, 'tagging': 1, 'parsing': 1, 'and': 3, 'semantic': 1, 'reasoning': 1, 'wrappers': 1, 'industrial-strength': 1, 'NLP': 1, 'an': 1, 'active': 1, 'discussion': 1, 'forum': 1, 'it': 1, 'offers': 1, 'simple': 1, 'interfaces': 1, 'to': 1, 'more': 1, 'than': 1, '50': 1, 'corpora': 1, 'lexical': 1, 'resources': 1, 'including': 1, 'WordNet': 1}\n"
     ]
    }
   ],
   "source": [
    "## check frequency distribution of words\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "fdist = FreqDist(word_tokens)\n",
    "print('Word Count Dictionary:', dict(fdist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddfbcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
